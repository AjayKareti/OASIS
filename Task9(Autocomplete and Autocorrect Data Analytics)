import pandas as pd

# Sample dataset collection
# Here we'll use a dataset of news articles, but you can collect from various sources
data = pd.read_csv("E:\email_spam.csv")

# Convert the dictionary to a DataFrame
df = pd.DataFrame(data)

import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Tokenize text into words
df['tokens'] = df['text'].apply(nltk.word_tokenize)

# Remove stop words and lemmatize tokens
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(tokens):
    tokens = [word for word in tokens if word.lower() not in stop_words]
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return tokens

df['tokens'] = df['tokens'].apply(preprocess)

from collections import defaultdict, Counter
from nltk.util import ngrams

# Create a bigram model
model = defaultdict(Counter)

for tokens in df['tokens']:
    bigrams = list(ngrams(tokens, 2))
    for w1, w2 in bigrams:
        model[w1][w2] += 1

# Function to autocomplete the next word
def autocomplete(word, model, top_k=3):
    suggestions = model[word].most_common(top_k)
    return [word for word, _ in suggestions]

# Example usage
input_word = "sample"
print(f"Autocomplete suggestions for '{input_word}': {autocomplete(input_word, model)}")

from nltk.metrics.distance import edit_distance

# Sample vocabulary
vocabulary = ['sample', 'text', 'data', 'training', 'model']

# Function to autocorrect a word
def autocorrect(word, vocabulary):
    closest_word = min(vocabulary, key=lambda v: edit_distance(word, v))
    return closest_word

# Example usage
misspelled_word = "txet"
corrected_word = autocorrect(misspelled_word, vocabulary)
print(f"Corrected word for '{misspelled_word}': {corrected_word}")

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

# Example: Calculate metrics for a binary classification task
y_true = [1, 0, 1, 1, 0]  # Ground truth labels
y_pred = [1, 0, 1, 0, 0]  # Predicted labels

precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
accuracy = accuracy_score(y_true, y_pred)

print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")
print(f"Accuracy: {accuracy}")

import matplotlib.pyplot as plt

# Sample data for visualization
performance_metrics = {
    'Precision': precision,
    'Recall': recall,
    'F1 Score': f1,
    'Accuracy': accuracy
}

# Plotting the metrics
plt.figure(figsize=(10, 5))
plt.bar(performance_metrics.keys(), performance_metrics.values())
plt.xlabel('Metrics')
plt.ylabel('Values')
plt.title('Model Performance Metrics')
plt.show()

